{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pip Installs"
      ],
      "metadata": {
        "id": "GdUwThaVQS_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VxCMlpJ00ZDm",
        "outputId": "2a507c57-1fbb-4916-aa34-820ebd52afc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets==3.0.0\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.7.1\n",
            "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.0.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (4.66.6)\n",
            "Collecting xxhash (from datasets==3.0.0)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==3.0.0)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.0)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.0.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2024.9.11)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.0.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets==3.0.0) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.0.0) (2024.8.30)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==3.0.0)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.0.0) (2024.2)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, xxhash, fsspec, dill, multiprocess, matplotlib, transformers, datasets\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.8.0\n",
            "    Uninstalling matplotlib-3.8.0:\n",
            "      Successfully uninstalled matplotlib-3.8.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.1 which is incompatible.\n",
            "sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.0 dill-0.3.8 fsspec-2024.6.1 matplotlib-3.7.1 multiprocess-0.70.16 tokenizers-0.13.3 transformers-4.31.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "245f121448ad4dd38025da723f742e9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets==3.0.0 transformers==4.31.0 matplotlib==3.7.1\n",
        "!apt-get install git-lfs\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install jsonlines\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Statements"
      ],
      "metadata": {
        "id": "f2tX3bAAQaPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All import statements\n",
        "\n",
        "import collections\n",
        "from collections import Counter\n",
        "\n",
        "import json\n",
        "import jsonlines\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from scipy import sparse\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from itertools import chain\n",
        "\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from datasets import load_dataset\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "# Setting up all the seeds for repeatable experiements\n",
        "# DO NOT CHANGE\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8r7h_fa1HRc",
        "outputId": "186d0d04-a5ee-4614-ba7a-547e089c2e76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e4767ee3390>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API_KEY and Configuration"
      ],
      "metadata": {
        "id": "6hcjxdRgQgK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv_path = '/content/drive/MyDrive/.env'\n",
        "\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "api_key = os.getenv('API_KEY')\n",
        "\n"
      ],
      "metadata": {
        "id": "7dXNL0xMUj6A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key = api_key)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash-001-tuning\")"
      ],
      "metadata": {
        "id": "j3ZUS72SVjZx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format Cat-Bench\n"
      ],
      "metadata": {
        "id": "ATEr6n0VQlHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './drive/MyDrive/cat-bench'\n",
        "folders = ['train_must_why', 'test_must_why', 'val_must_why']\n",
        "\n",
        "# file types\n",
        "file_types = ['nondependent_real_before', 'nondependent_real_after',\n",
        "              'dependent_real_before', 'dependent_real_after']\n",
        "\n",
        "# dictionary to hold data\n",
        "data = {folder: {} for folder in folders}\n",
        "\n",
        "# load data from the folders\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(data_dir, folder)\n",
        "\n",
        "    for file_type in file_types:\n",
        "        file_path = os.path.join(folder_path, f'{file_type}.jsonl')\n",
        "        data[folder][file_type] = []\n",
        "\n",
        "        # read the .jsonl file\n",
        "        with jsonlines.open(file_path) as reader:\n",
        "            for obj in reader:\n",
        "                # append labels based on file type, 0 if in nondependent 1 if else\n",
        "                if file_type.startswith('nondependent'):\n",
        "                    obj['label'] = 0\n",
        "                else:\n",
        "                    obj['label'] = 1\n",
        "\n",
        "                # store in the folder based off file_type list\n",
        "                data[folder][file_type].append(obj)\n",
        "\n",
        "combined_data = {}\n",
        "\n",
        "for folder in folders:\n",
        "    combined_data[folder] = []\n",
        "\n",
        "    # nondependent data being split in two by before and after, since they are the same samples just the questions worded differently.\n",
        "    nondependent_before = data[folder]['nondependent_real_before']\n",
        "    nondependent_after = data[folder]['nondependent_real_after']\n",
        "    half_before = len(nondependent_before) // 2\n",
        "    half_after = len(nondependent_after) // 2\n",
        "\n",
        "    # combine first half of before and second half of after\n",
        "    combined_nondependent = nondependent_before[:half_before] + nondependent_after[half_after:]\n",
        "\n",
        "    # dependent, samething as above jusdt for dependent\n",
        "    dependent_before = data[folder]['dependent_real_before']\n",
        "    dependent_after = data[folder]['dependent_real_after']\n",
        "    half_before = len(dependent_before) // 2\n",
        "    half_after = len(dependent_after) // 2\n",
        "\n",
        "    # combine first half of before and second half of after\n",
        "    combined_dependent = dependent_before[:half_before] + dependent_after[half_after:]\n",
        "\n",
        "    # add to combined data\n",
        "    combined_data[folder].extend(combined_nondependent)\n",
        "    combined_data[folder].extend(combined_dependent)\n",
        "\n",
        "example_plan = combined_data['train_must_why'][0]\n",
        "print(example_plan)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrwIB6HE4JGa",
        "outputId": "5a5d4e45-938f-4a1a-e249-17aed25d2f3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'plan_idx': 3467, 'original_file_row_no': 3467, 'title': 'normandy pork casserole with apples, celery and walnuts', 'question_idx': 3467, 'steps': ['Preheat the oven to 160C (325F, gas mark 3).', 'Heat the oil in a flameproof casserole, add the pork and fry, stirring frequently, for 5 minutes or until browned on all sides.', 'Add the celery and onion and fry gently for about 10 minutes or until softened.', 'Pour in the cider or apple juice and add the bay leaf.', 'Season with salt and pepper to taste.', 'Bring to the boil, then cover the casserole and transfer to the oven.', 'Cook for 1 1/4 hours or until the pork is tender.', 'About 40 minutes before the pork is ready, put the rice in an ovenproof dish and pour over the boiling stock.', 'Stir well, then cover and put into the oven to cook with the pork.', 'About 25 minutes before the end of the cooking time, quarter and core the apples but do not peel them.', 'Slice the quarters thickly, then add to the pork and continue cooking.', 'Meanwhile, heat a small frying pan over a moderate heat, add the walnuts and cook, stirring, until lightly toasted.', 'When the pork is tender, stir in the walnuts and taste for seasoning.', 'Garnish with the chopped celery leaves and serve hot, with the rice.'], 'question_type': 'nondependent_real_before', 'step_pair_idx_asked_about': [0, 1], 'binary_question': 'Must Step 1 happen before Step 2?', 'why_question': 'Why is it not necessary for Step 1 to happen before Step 2?', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data['train_must_why']))\n",
        "#print(data['train_must_why'])\n",
        "print(len(combined_data['train_must_why']))\n",
        "print(len(combined_data['test_must_why']))\n",
        "print(len(combined_data['val_must_why']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjwL_v3S_zXH",
        "outputId": "e11037b2-57db-437f-ab87-59345b943719"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "6934\n",
            "1420\n",
            "808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Fine-Tune Training Prompts"
      ],
      "metadata": {
        "id": "YU3i5lzsQrUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #return prompt, index removed\n",
        "# def create_gemini_prompt(steps, question, q_idx):\n",
        "#     # remove random step here\n",
        "#     valid_indices = [i for i in range(0, q_idx[1]) if i != q_idx[0]]\n",
        "\n",
        "#     if (len(valid_indices) == 0) or (valid_indices == None):\n",
        "#         return None, None\n",
        "\n",
        "#     index_to_remove = random.choice(valid_indices)\n",
        "\n",
        "\n",
        "#     steps_text = \" \".join([f\"Step {i+1}: {step}\" for i, step in enumerate(steps) if i != index_to_remove])\n",
        "#     prompt = f\"{steps_text}\\nQuestion: {question}\"\n",
        "#     return prompt, index_to_remove\n",
        "\n",
        "# # prep training data with labels\n",
        "# training_data = []\n",
        "# removed_data = []\n",
        "# for plan in combined_data['train_must_why']:\n",
        "#     steps = plan['steps']\n",
        "#     question = plan['binary_question']\n",
        "#     label = plan['label']\n",
        "#     q_idx = plan['step_pair_idx_asked_about']\n",
        "\n",
        "#     # if the step_idx is 0, 1, remove that from the list of training items\n",
        "#     # we want to remove a random step before the the last step\n",
        "#     # so if 3, 4, then we remove a random index before 4 but making sure its not 3\n",
        "#     # also, we before or after dataset, we will take half of the before and half of the after\n",
        "\n",
        "\n",
        "#     # make prompt\n",
        "#     prompt, removed_index = create_gemini_prompt(steps, question, q_idx)\n",
        "\n",
        "#     if prompt == None:\n",
        "#       continue\n",
        "\n",
        "#     # training set to\n",
        "#     training_data.append({\n",
        "#         'text_input': prompt,\n",
        "#         'output': str(label)\n",
        "#     })\n",
        "\n",
        "#     removed_data.append({\n",
        "#         'question_idx': plan['plan_idx'],\n",
        "#         'removed_idx' : removed_index\n",
        "#     })\n"
      ],
      "metadata": {
        "id": "nh903QvuPO5-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(training_data))\n",
        "# print(training_data[6798])\n",
        "# print(type(training_data))\n",
        "# print(len(removed_data))\n",
        "# print(removed_data[6798])\n",
        "# print(type(removed_data))"
      ],
      "metadata": {
        "id": "1gbWYP_CPQqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# print(training_df.head())\n",
        "\n",
        "# removed_df = pd.DataFrame(removed_data)\n",
        "\n",
        "# print(removed_df.head())\n"
      ],
      "metadata": {
        "id": "lxoruZyJxyxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_df.to_csv('./drive/MyDrive/rds_training_data.csv', index=False)\n",
        "# removed_df.to_csv('./drive/MyDrive/rds_removed_data.csv', index=False)"
      ],
      "metadata": {
        "id": "-7EiLIpGyhRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = \"models/gemini-1.5-flash-001-tuning\"\n",
        "# operation = genai.create_tuned_model(\n",
        "#     display_name=\"increment\",\n",
        "#     source_model=base_model,\n",
        "#     epoch_count=8,\n",
        "#     batch_size=5,\n",
        "#     learning_rate=0.001,\n",
        "#     training_data=training_data,\n",
        "# )\n",
        "\n",
        "# for status in operation.wait_bar():\n",
        "#     #operation.cancel()\n",
        "#     time.sleep(10)\n",
        "\n",
        "# result = operation.result()\n",
        "# print(result)\n",
        "\n"
      ],
      "metadata": {
        "id": "b4o0KkgDYkmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FICWI3AvYlUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Fine-Tune Training results"
      ],
      "metadata": {
        "id": "Z1O-pjpIQ2SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# name = 'step dependencies fine-tuned_2'\n",
        "# # model = genai.get_tuned_model(f'tunedModels/{name}')\n",
        "# model = genai.get_tuned_model(f'tunedModels/step-dependencies-finetuned2-ze1h5s8tmff')\n",
        "\n",
        "# #model.tuning_task.snapshots\n",
        "\n",
        "# snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
        "\n",
        "# sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n",
        "\n",
        "# model = genai.GenerativeModel(model_name=f'tunedModels/step-dependencies-finetuned2-ze1h5s8tmff')\n",
        "\n",
        "# result = model.generate_content('Preheat the oven to 160C (325F, gas mark 3).\", \"Heat the oil in a flameproof casserole, add the pork and fry, stirring frequently, for 5 minutes or until browned on all sides.\", \"Add the celery and onion and fry gently for about 10 minutes or until softened.\", \"Pour in the cider or apple juice and add the bay leaf.\", \"Season with salt and pepper to taste.\", \"Bring to the boil, then cover the casserole and transfer to the oven.\", \"Cook for 1 1/4 hours or until the pork is tender.\", \"About 40 minutes before the pork is ready, put the rice in an ovenproof dish and pour over the boiling stock.\", \"Stir well, then cover and put into the oven to cook with the pork.\", \"About 25 minutes before the end of the cooking time, quarter and core the apples but do not peel them.\", \"Slice the quarters thickly, then add to the pork and continue cooking.\", \"Meanwhile, heat a small frying pan over a moderate heat, add the walnuts and cook, stirring, until lightly toasted.\", \"When the pork is tender, stir in the walnuts and taste for seasoning.\", \"Garnish with the chopped celery leaves and serve hot, with the rice.\" Must Step 2 happen after Step 1?')\n",
        "\n",
        "# result.text"
      ],
      "metadata": {
        "id": "7KirBX-990G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_models = genai.list_models()\n",
        "print(available_models)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  #print(m)\n",
        "  continue"
      ],
      "metadata": {
        "id": "kaDg_h6y_QUe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f7390b6c-f376-49fb-bdc4-ab490beed2bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object list_models at 0x7e46cbba33e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "base_model = genai.GenerativeModel(model_name='models/gemini-1.5-flash-001-tuning')"
      ],
      "metadata": {
        "id": "etqTy59pB_FA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.generate_content('Preheat the oven to 160C (325F, gas mark 3).\", \"Heat the oil in a flameproof casserole, add the pork and fry, stirring frequently, for 5 minutes or until browned on all sides.\", \"Add the celery and onion and fry gently for about 10 minutes or until softened.\", \"Pour in the cider or apple juice and add the bay leaf.\", \"Season with salt and pepper to taste.\", \"Bring to the boil, then cover the casserole and transfer to the oven.\", \"Cook for 1 1/4 hours or until the pork is tender.\", \"About 40 minutes before the pork is ready, put the rice in an ovenproof dish and pour over the boiling stock.\", \"Stir well, then cover and put into the oven to cook with the pork.\", \"About 25 minutes before the end of the cooking time, quarter and core the apples but do not peel them.\", \"Slice the quarters thickly, then add to the pork and continue cooking.\", \"Meanwhile, heat a small frying pan over a moderate heat, add the walnuts and cook, stirring, until lightly toasted.\", \"When the pork is tender, stir in the walnuts and taste for seasoning.\", \"Garnish with the chopped celery leaves and serve hot, with the rice.\" Must Step 2 happen after Step 1?')\n",
        "\n"
      ],
      "metadata": {
        "id": "jqNJ4u5wB8sz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.text"
      ],
      "metadata": {
        "id": "FHpJncGeCvDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "20662c12-802c-44e6-c96a-043b474b653d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Yes, Step 2 must happen after Step 1. \\n\\nHere's why:\\n\\n* **Step 1:** Preheats the oven to the correct temperature. This is necessary to ensure the pork cooks properly in the later steps.\\n* **Step 2:** Involves frying the pork in hot oil. This requires a preheated oven so the casserole dish is already at the right temperature for cooking. \\n\\nWithout the preheated oven, the casserole dish and the oil wouldn't be hot enough to properly brown the pork. \\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Testing Prompts"
      ],
      "metadata": {
        "id": "uVlg3gLmQ-ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #return prompt, index removed\n",
        "# def create_gemini_prompt(steps, question, q_idx):\n",
        "#     # remove random step here\n",
        "#     valid_indices = [i for i in range(0, q_idx[1]) if i != q_idx[0]]\n",
        "\n",
        "#     if (len(valid_indices) == 0) or (valid_indices == None):\n",
        "#         return None, None\n",
        "\n",
        "#     index_to_remove = random.choice(valid_indices)\n",
        "\n",
        "\n",
        "#     steps_text = \" \".join([f\"Step {i+1}: {step}\" for i, step in enumerate(steps) if i != index_to_remove])\n",
        "#     prompt = f\"{steps_text}\\nQuestion: {question}\"\n",
        "#     return prompt, index_to_remove\n",
        "\n",
        "# # prep training data with labels\n",
        "# test_data = []\n",
        "# test_removed_data = []\n",
        "# for plan in combined_data['test_must_why']:\n",
        "#     steps = plan['steps']\n",
        "#     question = plan['binary_question']\n",
        "#     label = plan['label']\n",
        "#     q_idx = plan['step_pair_idx_asked_about']\n",
        "\n",
        "\n",
        "#     # make prompt\n",
        "#     prompt, removed_index = create_gemini_prompt(steps, question, q_idx)\n",
        "\n",
        "#     if prompt == None:\n",
        "#       continue\n",
        "\n",
        "#     # training set to\n",
        "#     test_data.append({\n",
        "#         'text_input': prompt,\n",
        "#         'output': str(label)\n",
        "#     })\n",
        "\n",
        "#     test_removed_data.append({\n",
        "#         'question_idx': plan['plan_idx'],\n",
        "#         'removed_idx' : removed_index\n",
        "#     })\n"
      ],
      "metadata": {
        "id": "kuNoOx_eVV6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df = pd.DataFrame(test_data)\n",
        "# test_removed_df = pd.DataFrame(test_removed_data)\n",
        "\n",
        "# print(test_df.head())\n",
        "# print(test_removed_df.head())"
      ],
      "metadata": {
        "id": "qVOO6eS1Sf9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.to_csv('./drive/MyDrive/rds_test_data.csv', index=False)\n",
        "# test_removed_df.to_csv('./drive/MyDrive/rds_test_removed_data.csv', index=False)"
      ],
      "metadata": {
        "id": "hhXjeoVZSY_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data[0]"
      ],
      "metadata": {
        "id": "3mDPjoElLaac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true_labels = [int(sample['output']) for sample in test_data]"
      ],
      "metadata": {
        "id": "udEHbhgJSnJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# true_labels\n",
        "# true_predictions_df = pd.DataFrame(true_labels, columns=[\"Numbers\"])\n",
        "# true_predictions_df.to_csv(\"./drive/MyDrive/true_predictions_1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ce4m67EzS45C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Fine-Tuned Model"
      ],
      "metadata": {
        "id": "feGhi5GVRDWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_samples = combined_data['test_must_why']\n",
        "# batch_size = 50\n",
        "# predictions = []\n",
        "\n",
        "# for i in range(0, len(test_data), batch_size):\n",
        "#   #make batch\n",
        "#     batch = test_data[i:i + batch_size]\n",
        "\n",
        "#   #call api\n",
        "#     try:\n",
        "#         batch_responses = [base_model.generate_content(inp['text_input'] + \" Answer ONLY 0 for no or 1 for yes.\") for inp in batch]\n",
        "#         predictions.extend(batch_responses)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "#         time.sleep(5)\n",
        "#   #wait 1 minute to avoid rate limit\n",
        "#     print(\"sleep for a minute\")\n",
        "#     time.sleep(60)"
      ],
      "metadata": {
        "id": "ACCsirExUC67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # predictions\n",
        "# predictions[0].text"
      ],
      "metadata": {
        "id": "Tuvm8N0oX9te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_str = [prediction.text.strip() for prediction in predictions]\n"
      ],
      "metadata": {
        "id": "--2ELugXwrh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_predictions = set(prediction.text.strip() for prediction in predictions)"
      ],
      "metadata": {
        "id": "E_MAEAbRvIGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_predictions"
      ],
      "metadata": {
        "id": "sOswYGezvfiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def clean_text(text):\n",
        "#     match = re.search(r\"^(\\d+)\\.\", text)\n",
        "#     if match:\n",
        "#         return match.group(1)\n",
        "#     return text.strip()\n",
        "\n",
        "\n",
        "\n",
        "# for idx, prediction in enumerate(predictions_str):\n",
        "#     predictions_str[idx] = clean_text(prediction)\n",
        "\n",
        "# unique_predictions = set(prediction.strip() for prediction in predictions_str)\n"
      ],
      "metadata": {
        "id": "39cemHrGvgrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_predictions"
      ],
      "metadata": {
        "id": "vdlNXzduwVES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions_int = [int(prediction) for prediction in predictions_str]\n",
        "\n",
        "# base_predictions_df = pd.DataFrame(predictions_int, columns=[\"Numbers\"])\n",
        "# base_predictions_df.to_csv(\"./drive/MyDrive/base_predictions_1.csv\", index=False)"
      ],
      "metadata": {
        "id": "1rsvqRraxKgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOTFXnB9xZyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions_int, average='binary')\n",
        "# accuracy = accuracy_score(true_labels, predictions_int)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "UI6xMIGN0_rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_info = genai.get_model(\"tunedModels/rdsdependencies-km00863isqdg\")\n",
        "# print(model_info)\n"
      ],
      "metadata": {
        "id": "RrjuZF9SPN05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = genai.GenerativeModel(model_name=\"tunedModels/rdsdependencies-km00863isqdg\")\n",
        "\n",
        "# #model.tuning_task.snapshots\n",
        "\n",
        "# #snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
        "\n",
        "# #sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')\n",
        "\n",
        "# # model = genai.GenerativeModel(model_name=f'tunedModels/rdsdependencies-km00863isqdg')\n",
        "\n",
        "# result = model.generate_content(test_data[0]['text_input'])\n",
        "\n",
        "# result.text"
      ],
      "metadata": {
        "id": "eTIIEJf21HzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# snapshots = pd.DataFrame(model.tuning_task.snapshots)\n",
        "\n",
        "# sns.lineplot(data=snapshots, x = 'epoch', y='mean_loss')"
      ],
      "metadata": {
        "id": "H_IZUA8eelxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #test_samples = combined_data['test_must_why']\n",
        "# batch_size = 50\n",
        "# tuned_predictions = []\n",
        "\n",
        "# for i in range(0, len(test_data), batch_size):\n",
        "#     batch = test_data[i:i + batch_size]\n",
        "\n",
        "#     try:\n",
        "#         # Generate predictions for the batch\n",
        "#         batch_responses = [model.generate_content(inp['text_input']) for inp in batch]\n",
        "#         tuned_predictions.extend(batch_responses)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "#         time.sleep(5)  # Wait before retrying\n",
        "\n",
        "#     # Rate limit handling (add delays if necessary)\n",
        "#     print(\"sleep for a minute\")\n",
        "#     time.sleep(60)\n",
        "\n",
        "# tuned_predictions_str = [prediction.text.strip() for prediction in tuned_predictions]\n"
      ],
      "metadata": {
        "id": "5A27IpYL7uq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def clean_text(text):\n",
        "#     # match = re.search(r\"output: \\*\\*(\\d+)\\*\\*\", text)\n",
        "#     # if match:\n",
        "#     #     return match.group(1)\n",
        "#     # return text.strip()\n",
        "#     if text.strip() == '0':\n",
        "#         return '0'\n",
        "#     elif text.strip() == '1':\n",
        "#         return '1'\n",
        "#     return '-1'\n",
        "\n",
        "\n",
        "# # Iterate through predictions and clean the text\n",
        "# for idx, prediction in enumerate(tuned_predictions_str):\n",
        "#     tuned_predictions_str[idx] = clean_text(prediction)\n",
        "\n",
        "# unique_predictions = set(prediction.strip() for prediction in tuned_predictions_str)\n",
        "# unique_predictions\n"
      ],
      "metadata": {
        "id": "0KePRTY96gxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tuned_predictions_int = [int(prediction) for prediction in tuned_predictions_str]\n",
        "# tuned_predictions_df = pd.DataFrame(tuned_predictions_int, columns=[\"Numbers\"])\n",
        "# tuned_predictions_df.to_csv(\"./drive/MyDrive/tuned_predictions_1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Eif-sdpZ7RGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #filtered_true_labels = true_labels.copy()\n",
        "# filtered_true_labels = np.array(true_labels)\n",
        "# tuned_predictions_int = np.array(tuned_predictions_int, dtype=int)\n",
        "\n",
        "# valid_indexes = tuned_predictions_int != -1\n",
        "# print(len(filtered_true_labels))\n",
        "# print(len(valid_indexes))\n",
        "# filtered_true_labels = filtered_true_labels[valid_indexes]\n",
        "# filtered_tuned_predictions_int = tuned_predictions_int[valid_indexes]"
      ],
      "metadata": {
        "id": "NmU4vSH2C9-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(filtered_true_labels, filtered_tuned_predictions_int, average='binary')\n",
        "# accuracy = accuracy_score(filtered_true_labels, filtered_tuned_predictions_int)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "mdz2Txct7Z45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# temp = pd.DataFrame(test_removed_data)\n",
        "\n",
        "# for plan in combined_data['test_must_why']:\n",
        "#   #print(temp[temp['question_idx'] == plan['plan_idx']])\n",
        "#   rmv_idx = None\n",
        "#   try:\n",
        "#     rmv_idx = temp[temp['question_idx'] == plan['plan_idx']]['removed_idx'].values[0]\n",
        "#   except Exception as e:\n",
        "#      rmv_idx = None\n",
        "#   q_idx = plan['step_pair_idx_asked_about']\n",
        "#   #print(rmv_idx)\n",
        "#   if rmv_idx:\n",
        "#     continue\n",
        "\n",
        "#   #print(q_idx)\n",
        "#   if (rmv_idx == q_idx[0]) or (rmv_idx == q_idx[1]):\n",
        "#     print('yea this shit fukec')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HLqvyZ7V7jLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2MnkRE4M-C7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tune Results"
      ],
      "metadata": {
        "id": "lu9yXDK-QKhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results with no fine tune and just a base model:\n",
        "\n",
        "Accuracy: 0.5985507246376811\n",
        "\n",
        "Precision: 0.6157556270096463\n",
        "\n",
        "Recall: 0.5487106017191977\n",
        "\n",
        "F1 Score: 0.5803030303030303\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "Results with a fine tune:\n",
        "\n",
        "Accuracy: 0.9358600583090378\n",
        "\n",
        "Precision: 0.9342857142857143\n",
        "\n",
        "Recall: 0.9396551724137931\n",
        "\n",
        "F1 Score: 0.9369627507163324"
      ],
      "metadata": {
        "id": "Jll1t6GsFsrI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WepE_txBF-Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Base Model Testing Data and Answers"
      ],
      "metadata": {
        "id": "pyn81mLSRrfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('./drive/MyDrive/rds_test_data.csv')\n",
        "true_predictions = pd.read_csv('./drive/MyDrive/true_predictions_1.csv')"
      ],
      "metadata": {
        "id": "mHiGh53qRx7O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Idea 2: Prompting"
      ],
      "metadata": {
        "id": "aEtsauTyRKgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt + API Call"
      ],
      "metadata": {
        "id": "l5-AJJ5PRrix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #test_samples = combined_data['test_must_why']\n",
        "# test_data = test_df\n",
        "\n",
        "# prompt = \"\"\"\n",
        "# Consider the following example as a precursor to a question:\n",
        "\n",
        "# 1. Gather ingredients: flour, eggs\n",
        "# 2. [Missing Step]\n",
        "# 3. Mix the whisked eggs with the flour.\n",
        "\n",
        "# In this example, for \"whisked eggs\" to be added to the \"flour,\" the eggs must first be cracked and whisked.\n",
        "# Therefore, these steps are dependent because the state of the \"eggs\" must change before they can be mixed with the\n",
        "# \"flour.\"\n",
        "\n",
        "# For the following plan and question, return ONLY 0 if the pair in question is non-dependent and 1 if pair is dependent.\n",
        "# Again, your response should only be either a 0 or 1.\n",
        "\n",
        "# \"\"\"\n",
        "# time.sleep(60)\n",
        "\n",
        "# batch_size = 50\n",
        "# prompted_predictions = []\n",
        "\n",
        "# for i in range(0, len(test_data), batch_size):\n",
        "#     batch = test_data[i:i + batch_size]\n",
        "\n",
        "\n",
        "#     # print(type(batch))\n",
        "#     # print(batch.columns)\n",
        "\n",
        "#     # for _, row in batch.iterrows():\n",
        "#     #   extracted_string = row['text_input']\n",
        "#     #   print(type(extracted_string))\n",
        "\n",
        "#     try:\n",
        "#         # Generate predictions for the batch\n",
        "#         batch_responses = [base_model.generate_content(prompt + \"\\n\" + inp['text_input']) for _, inp in batch.iterrows()]\n",
        "#         prompted_predictions.extend(batch_responses)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "#         time.sleep(5)  # Wait before retrying\n",
        "\n",
        "#     # Rate limit handling (add delays if necessary)\n",
        "#     print(\"sleep for a minute\")\n",
        "#     time.sleep(70)\n",
        "\n",
        "# prompted_predictions_str = [prediction.text.strip() for prediction in prompted_predictions]\n"
      ],
      "metadata": {
        "id": "-nK_EJLHROiy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #prompted_predictions_str\n",
        "# unique_predictions = set(prediction.strip() for prediction in prompted_predictions_str)\n",
        "# unique_predictions\n"
      ],
      "metadata": {
        "id": "iK6jJJvKWqQf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompted_predictions_int = [int(prediction) for prediction in prompted_predictions_str]\n",
        "# prompted_predictions_df = pd.DataFrame(prompted_predictions_int, columns=[\"Numbers\"])\n",
        "# prompted_predictions_df.to_csv(\"./drive/MyDrive/prompted_predictions_1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "-83VTIj-bKJL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true_labels = true_predictions['Numbers'].to_list()"
      ],
      "metadata": {
        "id": "4cLa0fVxaqki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #filtered_true_labels = true_labels.copy()\n",
        "# filtered_true_labels = np.array(true_labels)\n",
        "# prompted_predictions_int = np.array(prompted_predictions_int, dtype=int)\n",
        "\n",
        "# valid_indexes = prompted_predictions_int != -1\n",
        "# print(len(filtered_true_labels))\n",
        "# print(len(valid_indexes))\n",
        "# filtered_true_labels = filtered_true_labels[valid_indexes]\n",
        "# filtered_prompted_predictions_int = prompted_predictions_int[valid_indexes]"
      ],
      "metadata": {
        "id": "SvSf3wXNacEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Example Results"
      ],
      "metadata": {
        "id": "h_DBQLvFRzRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(filtered_true_labels, filtered_prompted_predictions_int, average='binary')\n",
        "# accuracy = accuracy_score(filtered_true_labels, filtered_prompted_predictions_int)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "pz655CkYa9cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results with just a base model:\n",
        "\n",
        "Accuracy: 0.5985507246376811\n",
        "\n",
        "Precision: 0.6157556270096463\n",
        "\n",
        "Recall: 0.5487106017191977\n",
        "\n",
        "F1 Score: 0.5803030303030303\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "Results with an example included in the prompt:\n",
        "\n",
        "Accuracy: 0.6442028985507247\n",
        "\n",
        "Precision: 0.6033966033966034\n",
        "\n",
        "Recall: 0.8653295128939829\n",
        "\n",
        "F1 Score: 0.711006474396704\n"
      ],
      "metadata": {
        "id": "sT3VvgocbSX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Idea 3: Reverse and Graphed Planning"
      ],
      "metadata": {
        "id": "I2M-8o5gRiqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first i need to reverse the steps\n",
        "test_str = test_df['text_input'].iloc[0]\n",
        "\n",
        "#steps_list = steps_string.split(\"Step \")\n",
        "#steps_list = [step.strip() for step in steps_list if step]"
      ],
      "metadata": {
        "id": "vbPEFPL7bIs5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "R0gQA9fublIJ",
        "outputId": "7f38f104-818b-489c-9a5d-6d520e26bbf3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Step 1: Preheat oven to 180 C / Gas 4. Step 3: Sieve together flour, cornflour, nutmeg, bicarbonate of soda, cinnamon and cloves. Step 4: In another bowl, mix together guava pulp and juice. Step 5: In another bowl, cream together butter and sugar. Step 6: Add eggs, one at a time. Step 7: Add flour mixture and guava mixture alternately to creamed mixture. Step 8: Pour batter into prepared tin. Step 9: Bake at 180 C / Gas 4 for 30-35 minutes.\\nQuestion: Must Step 4 happen before Step 5?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_list = re.findall(r'(Step \\d+: .*?)(?= Step \\d+:|$)', test_str)\n",
        "steps_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt_ppiiIb3Fn",
        "outputId": "ca4d4b9f-f10b-45df-c439-574e886a1384"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Step 1: Preheat oven to 180 C / Gas 4.',\n",
              " 'Step 3: Sieve together flour, cornflour, nutmeg, bicarbonate of soda, cinnamon and cloves.',\n",
              " 'Step 4: In another bowl, mix together guava pulp and juice.',\n",
              " 'Step 5: In another bowl, cream together butter and sugar.',\n",
              " 'Step 6: Add eggs, one at a time.',\n",
              " 'Step 7: Add flour mixture and guava mixture alternately to creamed mixture.',\n",
              " 'Step 8: Pour batter into prepared tin.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_match = re.search(r'Question: (.*)', test_str)\n",
        "question = \"\\nQuestion: \" + question_match.group(1) if question_match else \"No question found.\"\n",
        "question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vfBB3tPHb2rl",
        "outputId": "1e15eb73-edde-493c-c098-7ce6d88eaaa2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQuestion: Must Step 4 happen before Step 5?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_plan(test_str):\n",
        "\n",
        "  steps_list = re.findall(r'(Step \\d+: .*?)(?= Step \\d+:|$)', test_str)\n",
        "  question_match = re.search(r'Question: (.*)', test_str)\n",
        "  question = \"\\nQuestion: \" + question_match.group(1) if question_match else \"No question found.\"\n",
        "  steps_list_reversed = steps_list[::-1]\n",
        "\n",
        "  return \" \".join(steps_list_reversed) + question"
      ],
      "metadata": {
        "id": "ySAreT3acgZm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_plan(test_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "HXMJt9d2d3MI",
        "outputId": "229aa4d4-a992-4215-b8a8-700dd1ab9147"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Step 8: Pour batter into prepared tin. Step 7: Add flour mixture and guava mixture alternately to creamed mixture. Step 6: Add eggs, one at a time. Step 5: In another bowl, cream together butter and sugar. Step 4: In another bowl, mix together guava pulp and juice. Step 3: Sieve together flour, cornflour, nutmeg, bicarbonate of soda, cinnamon and cloves. Step 1: Preheat oven to 180 C / Gas 4.\\nQuestion: Must Step 4 happen before Step 5?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['reversed_text_input'] = test_df['text_input'].apply(reverse_plan)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Shmo4TJ5d5K1",
        "outputId": "d0365445-51ca-4b5e-bb3b-e0cd4cc18cc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          text_input  output  \\\n",
              "0  Step 1: Preheat oven to 180 C / Gas 4. Step 3:...       0   \n",
              "1  Step 1: Preheat the oven to 180 degrees C / Ga...       0   \n",
              "2  Step 1: Mix together the prawns, chicken, egg ...       0   \n",
              "3  Step 1: Place water in a medium saucepan, and ...       0   \n",
              "4  Step 1: Preheat oven to 150 C / Gas 2 and ligh...       0   \n",
              "\n",
              "                                 reversed_text_input  \n",
              "0  Step 8: Pour batter into prepared tin. Step 7:...  \n",
              "1  Step 21: Then remove from the tin, and allow t...  \n",
              "2  Step 12: Drain and add to soup. Step 11: Add r...  \n",
              "3  Step 11: Reduce heat, and simmer 5 minutes. St...  \n",
              "4  Step 12: Turn the oven off and let the cheesec...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f42eb61-643f-4296-86dc-684352579384\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_input</th>\n",
              "      <th>output</th>\n",
              "      <th>reversed_text_input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Step 1: Preheat oven to 180 C / Gas 4. Step 3:...</td>\n",
              "      <td>0</td>\n",
              "      <td>Step 8: Pour batter into prepared tin. Step 7:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Step 1: Preheat the oven to 180 degrees C / Ga...</td>\n",
              "      <td>0</td>\n",
              "      <td>Step 21: Then remove from the tin, and allow t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Step 1: Mix together the prawns, chicken, egg ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Step 12: Drain and add to soup. Step 11: Add r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Step 1: Place water in a medium saucepan, and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Step 11: Reduce heat, and simmer 5 minutes. St...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Step 1: Preheat oven to 150 C / Gas 2 and ligh...</td>\n",
              "      <td>0</td>\n",
              "      <td>Step 12: Turn the oven off and let the cheesec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f42eb61-643f-4296-86dc-684352579384')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7f42eb61-643f-4296-86dc-684352579384 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7f42eb61-643f-4296-86dc-684352579384');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebe00176-e7ab-4c22-af3b-e20386f948d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebe00176-e7ab-4c22-af3b-e20386f948d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebe00176-e7ab-4c22-af3b-e20386f948d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 1380,\n  \"fields\": [\n    {\n      \"column\": \"text_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1380,\n        \"samples\": [\n          \"Step 1: Place water in a medium saucepan, and stir in the rice. Step 2: Bring to the boil. Step 3: Cover, reduce heat, and simmer 20 minutes. Step 5: Heat the sesame oil in a separate medium saucepan over medium heat. Step 6: Stir in tofu. Step 7: Stirring occasionally, fry about 20 minutes, until evenly crisp and lightly browned. Step 8: Season with salt. Step 9: In a small saucepan, bring the coconut milk to the boil. Step 10: Mix in green curry paste. Step 11: Reduce heat, and simmer 5 minutes. Step 12: Drizzle generously over the tofu and rice to serve.\\nQuestion: Must Step 9 happen after Step 8?\",\n          \"Step 1: In a small bowl, combine strawberries and sugar; cover and refrigerate until serving. Step 2: In a bowl, combine the flour, sugar, baking powder and salt. Step 3: Rub the butter into the flour until the mixture resembles coarse crumbs. Step 4: Combine the milk, egg yolk and lemon zest; stir into crumb mixture until a soft dough forms (dough will be sticky). Step 5: Turn onto a lightly floured surface; knead 10 times. Step 7: Gently pat or roll each half into a 1 .75cm thick circle. Step 8: Place 5cm apart on an ungreased baking tray. Step 9: Bake at 200 C / Gas 6 for 8-10 minutes or until golden brown. Step 10: Remove to a wire rack; cool for 15 minutes. Step 11: Meanwhile, in a small bowl, combine butter and lemon zest; set aside. Step 12: In a small mixing bowl, beat cream until it begins to thicken. Step 13: Add sugar; beat until stiff peaks form. Step 14: To assemble, split shortcakes in half. Step 15: Place cake bottoms on dessert plates; spread with lemon butter, then top each with a 1/4 of the strawberries and whipped cream. Step 16: Cover with shortcake top and remaining berries and cream.\\nQuestion: Must Step 13 happen after Step 7?\",\n          \"Step 1: Preheat barbecue for medium-high heat and lightly oil the cooking grate. Step 2: Whisk together the butter, garlic, curry powder, cumin and salt in a small bowl. Step 3: Arrange four large sheets of foil on a flat surface. Step 4: Divide the mussels into four even portions and place one portion on each piece of foil. Step 5: Dot the mussels with the curry mixture. Step 7: Top each with lime slices. Step 8: Wrap foil tightly around the portions. Step 9: Cook the packets on the preheated barbecue until the mussels have opened, 5 to 10 minutes. Step 10: Discard any mussels which do not open. Step 11: Transfer the mussels to small bowls and garnish each with a lime wedge to serve.\\nQuestion: Must Step 7 happen before Step 8?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reversed_text_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1380,\n        \"samples\": [\n          \"Step 11: Reduce heat, and simmer 5 minutes. Step 10: Mix in green curry paste. Step 9: In a small saucepan, bring the coconut milk to the boil. Step 8: Season with salt. Step 7: Stirring occasionally, fry about 20 minutes, until evenly crisp and lightly browned. Step 6: Stir in tofu. Step 5: Heat the sesame oil in a separate medium saucepan over medium heat. Step 3: Cover, reduce heat, and simmer 20 minutes. Step 2: Bring to the boil. Step 1: Place water in a medium saucepan, and stir in the rice.\\nQuestion: Must Step 9 happen after Step 8?\",\n          \"Step 15: Place cake bottoms on dessert plates; spread with lemon butter, then top each with a 1/4 of the strawberries and whipped cream. Step 14: To assemble, split shortcakes in half. Step 13: Add sugar; beat until stiff peaks form. Step 12: In a small mixing bowl, beat cream until it begins to thicken. Step 11: Meanwhile, in a small bowl, combine butter and lemon zest; set aside. Step 10: Remove to a wire rack; cool for 15 minutes. Step 9: Bake at 200 C / Gas 6 for 8-10 minutes or until golden brown. Step 8: Place 5cm apart on an ungreased baking tray. Step 7: Gently pat or roll each half into a 1 .75cm thick circle. Step 5: Turn onto a lightly floured surface; knead 10 times. Step 4: Combine the milk, egg yolk and lemon zest; stir into crumb mixture until a soft dough forms (dough will be sticky). Step 3: Rub the butter into the flour until the mixture resembles coarse crumbs. Step 2: In a bowl, combine the flour, sugar, baking powder and salt. Step 1: In a small bowl, combine strawberries and sugar; cover and refrigerate until serving.\\nQuestion: Must Step 13 happen after Step 7?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt + API Call"
      ],
      "metadata": {
        "id": "iziAr3prSxwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #test_samples = combined_data['test_must_why']\n",
        "# test_data = test_df\n",
        "\n",
        "# prompt = \"\"\"\n",
        "# Given a plan, for each step in the plan generate a node, where each step is a node.\n",
        "# Each node should connect to each other if that node depends on another node.\n",
        "# This could be because an item in the step depends on the state of another item or a change in the state of the item itself.\n",
        "# DO NOT output this graph.\n",
        "\n",
        "# For the following plan and question, return ONLY 0 if the pair in question is non-dependent and 1 if pair is dependent.\n",
        "# Again, your response should only be either a 0 or 1.\n",
        "\n",
        "# \"\"\"\n",
        "# #time.sleep(60)\n",
        "\n",
        "# batch_size = 50\n",
        "# reversed_prompted_predictions = []\n",
        "\n",
        "# for i in range(0, len(test_data), batch_size):\n",
        "#     batch = test_data[i:i + batch_size]\n",
        "\n",
        "#     try:\n",
        "#         # Generate predictions for the batch\n",
        "#         batch_responses = [base_model.generate_content(prompt + \"\\n\" + inp['reversed_text_input']) for _, inp in batch.iterrows()]\n",
        "#         reversed_prompted_predictions.extend(batch_responses)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "#         time.sleep(5)  # Wait before retrying\n",
        "\n",
        "#     # Rate limit handling (add delays if necessary)\n",
        "#     print(\"sleep for a minute\")\n",
        "#     time.sleep(70)\n",
        "\n",
        "# reversed_prompted_predictions_str = [prediction.text.strip() for prediction in reversed_prompted_predictions]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "ajIgno90eHi_",
        "outputId": "66e2afc6-d705-485f-e165-7b64957b4ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n",
            "sleep for a minute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique_predictions = set(prediction.strip() for prediction in reversed_prompted_predictions_str)\n",
        "# unique_predictions\n"
      ],
      "metadata": {
        "id": "SGbIgV6Ggewp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef14aabe-1484-40e9-e9f4-3dd1ed20fc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0', '1'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reversed_prompted_predictions_int = [int(prediction) for prediction in reversed_prompted_predictions_str]\n",
        "# reversed_prompted_predictions_df = pd.DataFrame(reversed_prompted_predictions_int, columns=[\"Numbers\"])\n",
        "# reversed_prompted_predictions_df.to_csv(\"./drive/MyDrive/reversed_prompted_predictions_1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "nuSnZobagljX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true_labels = true_predictions['Numbers'].to_list()"
      ],
      "metadata": {
        "id": "bSV9t6wIhR3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #filtered_true_labels = true_labels.copy()\n",
        "# filtered_true_labels = np.array(true_labels)\n",
        "# reversed_prompted_predictions_int = np.array(reversed_prompted_predictions_int, dtype=int)\n",
        "\n",
        "# valid_indexes = reversed_prompted_predictions_int != -1\n",
        "# print(len(filtered_true_labels))\n",
        "# print(len(valid_indexes))\n",
        "# filtered_true_labels = filtered_true_labels[valid_indexes]\n",
        "# filtered_reversed_prompted_predictions_int = reversed_prompted_predictions_int[valid_indexes]"
      ],
      "metadata": {
        "id": "mdf8pcYVhSNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de744727-73c8-4ee9-b396-7a148a2860f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1380\n",
            "1380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(filtered_true_labels, filtered_reversed_prompted_predictions_int, average='binary')\n",
        "# accuracy = accuracy_score(filtered_true_labels, filtered_reversed_prompted_predictions_int)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "9kAQEDeIhf3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65fe99f9-cbb3-4ffc-ca20-796ab39fc493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6826086956521739\n",
            "Precision: 0.6815642458100558\n",
            "Recall: 0.6991404011461319\n",
            "F1 Score: 0.6902404526166902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reverse and graph results"
      ],
      "metadata": {
        "id": "sZsSSsVHS2ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results with just a base model:\n",
        "\n",
        "Accuracy: 0.5985507246376811\n",
        "\n",
        "Precision: 0.6157556270096463\n",
        "\n",
        "Recall: 0.5487106017191977\n",
        "\n",
        "F1 Score: 0.5803030303030303\n",
        "\n",
        "\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "Results with an reversed plan and graph method:\n",
        "\n",
        "Accuracy: 0.6826086956521739\n",
        "\n",
        "Precision: 0.6815642458100558\n",
        "\n",
        "Recall: 0.6991404011461319\n",
        "\n",
        "F1 Score: 0.6902404526166902\n",
        "\n"
      ],
      "metadata": {
        "id": "X29IOWMUjE2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis / Hypotheses\n",
        "\n",
        "\n",
        "1. The dependent one shot example is biased towards guessing dependency.\n",
        "\n",
        "2. The reverse plan is more balanced, gets the same questions right as the one-shot but detects false negatives better.\n",
        "\n",
        "3. The one-shot bias would be fixed or changed if we made it one-shot with a non-dependent example rather than a dependent example."
      ],
      "metadata": {
        "id": "ZIqPTPaAzbtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read prior results\n",
        "\n"
      ],
      "metadata": {
        "id": "BXk3heKbzhss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#true_predictions\n",
        "rpp = pd.read_csv(\"./drive/MyDrive/reversed_prompted_predictions_1.csv\")\n",
        "pp = pd.read_csv(\"./drive/MyDrive/prompted_predictions_1.csv\")\n",
        "bp = pd.read_csv(\"./drive/MyDrive/base_predictions_1.csv\")\n"
      ],
      "metadata": {
        "id": "m636O0UYi5c_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_predictions.rename(columns={'Numbers':'true_predictions'}, inplace=True)\n",
        "pp.rename(columns={'Numbers':'prompt_predictions'}, inplace=True)\n",
        "rpp.rename(columns={'Numbers':'reverse_predictions'}, inplace=True)\n",
        "bp.rename(columns={'Numbers':'base_predictions'}, inplace=True)"
      ],
      "metadata": {
        "id": "8wvcGZaa9p0D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.concat([true_predictions, bp, pp, rpp], axis=1)\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qjYCguew-ctH",
        "outputId": "401b2e9c-3e4c-40e0-bd78-1d57f3fadb78"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      true_predictions  base_predictions  prompt_predictions  \\\n",
              "0                    0                 0                   0   \n",
              "1                    0                 1                   0   \n",
              "2                    0                 1                   1   \n",
              "3                    0                 1                   0   \n",
              "4                    0                 1                   1   \n",
              "...                ...               ...                 ...   \n",
              "1375                 1                 1                   1   \n",
              "1376                 1                 0                   0   \n",
              "1377                 1                 0                   1   \n",
              "1378                 1                 0                   0   \n",
              "1379                 1                 0                   1   \n",
              "\n",
              "      reverse_predictions  \n",
              "0                       0  \n",
              "1                       1  \n",
              "2                       0  \n",
              "3                       0  \n",
              "4                       0  \n",
              "...                   ...  \n",
              "1375                    1  \n",
              "1376                    1  \n",
              "1377                    1  \n",
              "1378                    1  \n",
              "1379                    1  \n",
              "\n",
              "[1380 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b10c4e5b-cded-4e27-b692-24ae094380ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_predictions</th>\n",
              "      <th>base_predictions</th>\n",
              "      <th>prompt_predictions</th>\n",
              "      <th>reverse_predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1380 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b10c4e5b-cded-4e27-b692-24ae094380ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b10c4e5b-cded-4e27-b692-24ae094380ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b10c4e5b-cded-4e27-b692-24ae094380ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9506b46-dd5a-4233-bc55-5a42170a9631\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9506b46-dd5a-4233-bc55-5a42170a9631')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9506b46-dd5a-4233-bc55-5a42170a9631 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0163fed2-a07b-45f9-82c2-8113b7895832\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0163fed2-a07b-45f9-82c2-8113b7895832 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 1380,\n  \"fields\": [\n    {\n      \"column\": \"true_predictions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_predictions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_predictions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reverse_predictions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # of times one shot and reversed guessed the same\n",
        "len(result_df[(result_df['prompt_predictions'] == 1) & (result_df['reverse_predictions'] == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08y5Yoq-pJsN",
        "outputId": "79ed8f16-5045-43a7-a2a4-a561795b8638"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "623"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # of times one shot and reversed guessed the same in dependent plans questions\n",
        "len(result_df[(result_df['prompt_predictions'] == 1) & (result_df['reverse_predictions'] == 1) & (result_df['true_predictions'] == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXX0v5hmuLQt",
        "outputId": "e179f5a9-e3d5-4525-a1d4-feefa50cf060"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "452"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # of times one shot got right in dependent plans questions\n",
        "len(result_df[(result_df['prompt_predictions'] == 1) & (result_df['true_predictions'] == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyZLAOjbut_E",
        "outputId": "438ddaf7-5b1a-49db-af7d-f1868c0d8288"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['true_predictions'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "7S5I_5Fk_ltO",
        "outputId": "971e69a6-8005-4787-f2b2-98ec13c46d1f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "true_predictions\n",
              "1    698\n",
              "0    682\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_predictions</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['prompt_predictions'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "2yc6dLYJgFcc",
        "outputId": "b888372a-0fc1-455e-af67-74b9589dd7ab"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prompt_predictions\n",
              "1    1001\n",
              "0     379\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_predictions</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['reverse_predictions'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "O9ZoyFxHgFnG",
        "outputId": "0aa7b3c1-999f-477d-f43e-0b3a9d021a16"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "reverse_predictions\n",
              "1    716\n",
              "0    664\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reverse_predictions</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df['base_predictions'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "l9t6O3U1jBIG",
        "outputId": "e128b227-22c0-4aa2-9c37-e0f8159c3f4e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "base_predictions\n",
              "0    758\n",
              "1    622\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>base_predictions</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>622</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_results = result_df[result_df['true_predictions'] == 1]\n",
        "false_results = result_df[result_df['true_predictions'] == 0]"
      ],
      "metadata": {
        "id": "xJWJUKGx_ocm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tkbn-1_2jAOz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(result_df == 1,\n",
        "            cmap=['white', 'black'],\n",
        "            cbar=False,\n",
        "            yticklabels=False,\n",
        "            xticklabels=result_df.columns)\n",
        "plt.title('Dependency Guess Occurrences')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "USx8B1dPCvDv",
        "outputId": "ec7470ad-7602-422a-852e-ff2b5f0788a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the first 50 with one-shot non-dependent example and the compare with the first 50 with the prior one-shot.\n",
        "# Then done, do write up."
      ],
      "metadata": {
        "id": "Huimk7mvH8xA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #test_samples = combined_data['test_must_why']\n",
        "# test_data = test_df\n",
        "\n",
        "# prompt = \"\"\"\n",
        "# Consider the following example as a precursor to a question:\n",
        "\n",
        "# 1. Gather ingredients: flour, eggs\n",
        "# 2. [Missing Step]\n",
        "# 3. Pre-heat oven to 350 degrees F.\n",
        "\n",
        "# In this example, pre-heating the oven to 350 degrees F has no dependency on us gathering the ingredients flour and eggs.\n",
        "\n",
        "# For the following plan and question, return ONLY 0 if the pair in question is non-dependent and 1 if pair is dependent.\n",
        "# Again, your response should only be either a 0 or 1.\n",
        "\n",
        "# \"\"\"\n",
        "# #time.sleep(60)\n",
        "\n",
        "# batch_size = 50\n",
        "# ond_prompted_predictions = []\n",
        "\n",
        "# for i in range(0, 50, batch_size):\n",
        "#     batch = test_data[i:i + batch_size]\n",
        "\n",
        "#     try:\n",
        "#         # Generate predictions for the batch\n",
        "#         batch_responses = [base_model.generate_content(prompt + \"\\n\" + inp['text_input']) for _, inp in batch.iterrows()]\n",
        "#         ond_prompted_predictions.extend(batch_responses)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error processing batch {i//batch_size + 1}: {e}\")\n",
        "#         time.sleep(5)  # Wait before retrying\n",
        "\n",
        "#     # Rate limit handling (add delays if necessary)\n",
        "#     print(\"sleep for a minute\")\n",
        "#     time.sleep(70)\n",
        "\n",
        "# ond_prompted_predictions_str = [prediction.text.strip() for prediction in ond_prompted_predictions]\n"
      ],
      "metadata": {
        "id": "QyPPRCEQL01h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dec9ab6e-416a-4a84-cfb7-a6bed15e506d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sleep for a minute\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #ond_prompted_predictions_str\n",
        "# unique_predictions = set(prediction.strip() for prediction in ond_prompted_predictions_str)\n",
        "# unique_predictions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-b8OMXZZ8lI",
        "outputId": "9e0ae50c-a435-4fad-e461-85dc0183b63f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0', '1'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ond_prompted_predictions_int = [int(prediction) for prediction in ond_prompted_predictions_str]\n",
        "# ond_prompted_predictions_df = pd.DataFrame(ond_prompted_predictions_int, columns=[\"Numbers\"])\n",
        "# ond_prompted_predictions_df.to_csv(\"./drive/MyDrive/ond_prompted_predictions_1.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "u6TaTEu_Z_uR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# true_labels = true_predictions['true_predictions'].to_list()"
      ],
      "metadata": {
        "id": "7Q7yutP8a9J0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #filtered_true_labels = true_labels.copy()\n",
        "# filtered_true_labels = np.array(true_labels)\n",
        "# filtered_true_labels = filtered_true_labels[0:50]\n",
        "# ond_prompted_predictions_int = np.array(ond_prompted_predictions_int, dtype=int)\n",
        "\n",
        "# valid_indexes = ond_prompted_predictions_int != -1\n",
        "# print(len(filtered_true_labels))\n",
        "# print(len(valid_indexes))\n",
        "# filtered_true_labels = filtered_true_labels[valid_indexes]\n",
        "# filtered_ond_prompted_predictions_int = ond_prompted_predictions_int[valid_indexes]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw2fM97gaAE9",
        "outputId": "c1aef23d-3427-43f5-e757-da02d96585ae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(filtered_true_labels, filtered_ond_prompted_predictions_int, average='binary')\n",
        "# accuracy = accuracy_score(filtered_true_labels, filtered_ond_prompted_predictions_int)\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_aqqXbYbPm2",
        "outputId": "b30c9aa3-e2a7-41c7-d9f9-9a1c69fad7e2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# precision, recall, f1, _ = precision_recall_fscore_support(filtered_true_labels, result_df['prompt_predictions'].to_list()[0:50], average='binary')\n",
        "# accuracy = accuracy_score(filtered_true_labels, result_df['prompt_predictions'].to_list()[0:50])\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYmdyQQmboZ_",
        "outputId": "9c06823c-90a3-4336-bdb2-49e56c7630b7"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.56\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6_6FGNvb3qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hypotheses Results"
      ],
      "metadata": {
        "id": "Wzva4qK8cQj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 1 results:\n",
        "\n",
        "There is definately a bias. The model with the dependent example guessed dependent 1001 times. The base model with no example in the prompt guessed only 622 times. The distribution differences are also different in the figure shown above."
      ],
      "metadata": {
        "id": "-eKSHQ1XiTan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 2 results:\n",
        "The dependent example for idea #2 prompt caused the model to guess dependent 1001 times compared to the reversed plan and graph method, which caused the model to guess dependent 716 times. We can also see from the figure above that the distritbution of its guesses are much more even than the one-shot prompt, especially for the non-dependent samples."
      ],
      "metadata": {
        "id": "VT7qkr4df0QN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothesis 3 results:\n",
        "\n",
        "Upon using a prompt that exemplifies a non-dependent example rather than a dependent example like the one used in idea #2, the score improved in a sample set of the first 50 plans (all of the first 50 are non-dependent).\n",
        "\n",
        "Out of the first 50 non-dependent plans, the original prompted model answered the questions correctly 56% of the time, whereas the new non-dependent prompted model answered it 70% of the time.\n",
        "\n",
        "It is still to be explored if the opposite occurred to the dependent subset of the database (if a new bias was created)."
      ],
      "metadata": {
        "id": "IvnlwRE4cVg6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPgyGewVd8ei"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}